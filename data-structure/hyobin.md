## 📌 기타 알고리즘

### DS-053
Thread Safe 한 자료구조가 있을까요? 없다면, 어떻게 Thread Safe 하게 구성할 수 있을까요?

Thread-safe 자료구조는 “여러 스레드가 동시에 접근(읽기/쓰기)해도 내부 상태가 깨지지 않고, 결과가 규칙대로(일관되게) 나오는 자료구조”

만약 여러 스레드가 동시에 쓰거나(혹은 읽기+쓰기) 하면:
- 데이터 레이스: 업데이트가 “씹힘”(lost update)
- 중간 상태 노출: 한 스레드가 수정 중인 “반쯤 갱신된” 구조를 다른 스레드가 봄 
- 구조 손상: 내부 연결(배열/버킷/노드 링크)이 꼬여서 예외, 무한루프, 잘못된 값 발생

**Thread Safe 한 자료구조는 있다**
대표적으로 ConcurrentHashMap, ConcurrentLinkedQueue, CopyOnWriteArrayList, BlockingQueue 같은 동시성 컬렉션이 있음

없거나(혹은 부족하면) 만드는 방법
- 락으로 감싸기: synchronized 등으로 모든 접근을 직렬화 
- 불변(Immutable)로 만들기: 생성 후 변경 금지 → 공유가 쉬움 
- Thread confinement: 스레드별 로컬로 쓰고 마지막에 합치기(Map-Reduce 스타일)

“정확성”이 우선이면 락/동시성 컬렉션, “초고성능”이 필요하면 contention 줄이는 구조(샤딩 등)로 감

### DS-054
배열의 길이를 알고 있다면, 조금 더 빠른 Thread Safe 한 연산을 만들 순 없을까요?

가능하다: 고정 크기면 동적 리사이징이 없어서 경쟁 포인트가 줄어든다

- 리사이징(resizing)은 자료구조가 “내부 저장공간(배열)”이 부족해지면 더 큰 배열을 새로 만들고 기존 데이터를 옮기는 과정

리사이징은 “한 번에 큰 구조 변경”이라서 동시성 환경에서는:
- 여러 스레드가 동시에 add() 하다가 누가 복사/교체를 하느냐 
- 복사 중에 다른 스레드가 읽거나 쓰면 중간 상태가 보일 수 있음 
- 그래서 보통 큰 락이 필요하거나(직렬화), 구현이 복잡해짐 
- 즉, 리사이징이 있으면 **그 타이밍에 contention(락 경쟁)** 이 크게 생길 수 있음

=> 처음부터 충분한 크기의 배열을 잡으면 리사이징 자체가 없는 것

### DS-055
사용하고 있는 언어의 자료구조는 Thread Safe 한가요? 그렇지 않다면, Thread Safe 한 Wrapped Data Structure 를 제공하고 있나요?

Java
- 기본 컬렉션(ArrayList, HashMap)은 thread-safe 아님 
- 대안: Collections.synchronizedList/map, ConcurrentHashMap, CopyOnWriteArrayList 등 제공함

C 
- 표준 라이브러리 자료구조 자체가 거의 없음(Java처럼 HashMap 같은 기본 컨테이너가 표준에 없음)
- 그래서 “thread-safe 컨테이너”도 표준으로 제공되지 않음
- 외부 라이브러리나 직접 락 설계해서 thread-safe로 만드는 게 일반적

Python(CPython 기준)
- list, dict는 논리적으로 thread-safe 아님(여러 스레드가 동시에 “복합 작업”하면 깨짐)
- 다만 GIL 때문에 메모리 충돌/크래시 가능성은 줄지만, 원자성/일관성은 보장 안 됨

### DS-056
문자열을 저장하고, 처리하는 주요 자료구조 및 알고리즘 (Trie, KMP, Rabin Karp 등) 에 대해 설명해 주세요.

**Trie(트라이)**
- 문자열을 문자 단위 트리로 저장 → prefix 검색/자동완성에 강함 
- 단점: 메모리 큼(노드 많음). 실무에선 압축 Trie 등 변형 고려

**KMP**
- 패턴 매칭에서 실패함수(lps)로 되돌아가기 최적화 → 최악 O(n+m) 보장 
- 안정적으로 “최악 케이스도 빨라야 하는” 텍스트 스캔에 적합

**Rabin–Karp(라빈 카프)**
- 해시로 윈도우 비교 → 평균 빠름, 다중 패턴에도 유리 
- 단점: 해시 충돌 가능(보통 검증 비교로 보완)


### DS-057
이진탐색이 무엇인지 설명하고, 시간복잡도를 증명해 보세요.

**정렬된 배열에서 중간값과 비교해서 탐색 구간을 절반으로 줄이는 탐색**

복잡도 증명
- 길이 n → 한 번 비교할 때마다 n/2로 감소 
- n / 2^k ≤ 1 되는 최소 k가 반복 횟수 
- 2^k ≥ n → k ≥ log2(n)
- 그래서 O(log n)

### DS-058
Lower Bound, Upper Bound 는 무엇이고, 이를 어떻게 구현할 수 있을까요?

- Lower Bound: x 이상이 처음 나오는 위치(첫 >= x)
- Upper Bound: x 초과가 처음 나오는 위치(첫 > x)
- 둘 차이로 x의 개수도 구함: upper - lower

구현 아이디어(반복문 이진탐색):
- lower: if a[mid] >= x: hi = mid else lo = mid+1 
- upper: if a[mid] > x: hi = mid else lo = mid+1

### DS-059
이진탐색의 논리를 적용하여 삼진탐색을 작성한다고 가정한다면, 시간복잡도는 어떻게 변화할까요? (실제 존재하는 삼진탐색 알고리즘은 무시하세요!)

매번 구간을 1/3로 줄인다고 치면
- n / 3^k ≤ 1 → k = O(log3 n)
- 시간복잡도는 **O(log n)** 로 동일

### DS-060
기존 이진탐색 로직에서 부등호의 범위가 바뀐다면, 어떤 영향이 있을까요?

**가장 흔한 문제: 무한 루프 / off-by-one / 경계 깨짐**

예시
- <= vs < 바꾸면 lower/upper 의미가 바뀌거나 중복 원소에서 위치가 달라짐
- 종료 조건(lo < hi vs lo <= hi)이랑 업데이트(hi=mid vs hi=mid-1)가 안 맞으면 X
- 그래서 경계 조건은 테스트를 “최솟값/최댓값/중복/없는 값” 케이스로 설정해야 함

---

### DS-061
그리디 알고리즘과 동적 계획법을 비교해 주세요.

- 그리디: 매 단계 “지금 최선” 선택. 빠르고 단순하지만 전역 최적 보장 조건이 필요
- DP: 부분문제 최적해를 저장/재활용. 전역 최적을 더 일반적으로 보장하지만 메모리/시간 더 씀

---

### DS-062
그렇다면, 어떤 경우에 각각의 기법을 사용할 수 있을까요?

**그리디**
- 탐욕 선택 속성이 성립할 때
- “근사해도 OK + 빠른 의사결정”이 중요할 때

- 예시
  - 동전 거스름돈(정해진 화폐 체계일 때)
  - 500, 100, 50, 10원에서 760원 거슬러주기
  - → 큰 동전부터 최대한 쓰는 게 최적
  - 매 단계 “지금 가장 큰 동전”이 전역 최적이 되는 구조라 그리디

**DP**
- 최적 부분 구조 + 중복 부분문제가 있을 때(예: 배낭, 편집거리, 최단경로 일부)
- 상태가 작거나, 메모리/시간 예산이 허용될 때

- 예시
  - 최소 동전 개수(화폐 체계가 일반적일 때)
  - 동전이 1, 3, 4이고 금액이 6이면 그리디(4+1+1=3개) vs 최적(3+3=2개)
  - → 그리디가 실패할 수 있어서 DP로 “금액별 최적”을 쌓음

---

### DS-063
동적 계획법으로 풀 수 있는 모든 문제는 재귀로 변환하여 풀 수 있나요?

대부분 가능하다. DP는 본질적으로 “점화식(재귀 관계)”이 있기 때문에

- Top-down(재귀+메모이제이션) ↔ Bottom-up(반복문 테이블)

- Top-down
  - “큰 문제 풀려면 작은 문제 필요하네? 내려가서 구하자(재귀)”

- Bottom-up
  - “작은 문제부터 미리 다 만들어 두고 올라가자(반복문)”

- 다만 재귀는 스택오버플로 위험, 호출 오버헤드, 디버깅/성능 이슈로 반복문 Bottom-up을 더 많이 씀(특히 입력이 큰 경우)